{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Chest X-Ray Classification with DenseNet121\n",
    "\n",
    " ## Hyperparameter Tuning Notebook\n",
    "    \n",
    "This notebook performs hyperparameter optimization for a DenseNet121 model on chest X-ray classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "import keras_tuner as kt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Directory Setup & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# A) Directory Setup & Hyperparams\n",
    "# -----------------------------\n",
    "OUTPUT_DIR = './balanced_dataset'\n",
    "CLASSES = ['Atelectasis', 'Cardiomegaly', 'No Finding', 'Nodule', 'Pneumothorax']\n",
    "\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, 'train')\n",
    "VAL_DIR   = os.path.join(OUTPUT_DIR, 'val')\n",
    "TEST_DIR  = os.path.join(OUTPUT_DIR, 'test')\n",
    "\n",
    "IMG_SIZE  = (512, 512)\n",
    "NUM_CLASSES = len(CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# B) Data Generators\n",
    "# -----------------------------\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.2,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.15,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    preprocessing_function=lambda x: tf.image.random_contrast(x, lower=0.8, upper=1.2)\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building Function for Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# C) Model Building Function for Keras Tuner\n",
    "# -----------------------------\n",
    "def build_model(hp):\n",
    "    # Hyperparameters to tune\n",
    "    l2_reg = hp.Float('l2_reg', min_value=1e-6, max_value=1e-2, sampling='log')\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.7, step=0.1)\n",
    "    dense_units_1 = hp.Int('dense_units_1', min_value=512, max_value=2048, step=256)\n",
    "    dense_units_2 = hp.Int('dense_units_2', min_value=256, max_value=1024, step=256)\n",
    "    dense_units_3 = hp.Int('dense_units_3', min_value=128, max_value=512, step=128)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-5, max_value=1e-3, sampling='log')\n",
    "\n",
    "    # Build the model\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    base_model.trainable = True\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(dense_units_1, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units_2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(dense_units_3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuner Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# D) Tuner Setup\n",
    "# -----------------------------\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,  # Number of trials to run\n",
    "    directory='hyperparameter_tuning',\n",
    "    project_name='densenet121_tuning'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Callbacks Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# E) Callbacks\n",
    "# -----------------------------\n",
    "# Create a timestamp for unique log directory\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = os.path.join('logs', timestamp)\n",
    "\n",
    "# Enhanced TensorBoard callback with more metrics\n",
    "tensorboard_cb = TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,\n",
    "    update_freq='batch',\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    profile_batch=2\n",
    ")\n",
    "\n",
    "# Create checkpoints directory if it doesn't exist\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Callbacks for hyperparameter search (without checkpoint)\n",
    "search_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7),\n",
    "    tensorboard_cb\n",
    "]\n",
    "\n",
    "# Callbacks for final training (with checkpoint)\n",
    "final_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7),\n",
    "    tensorboard_cb,\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join('checkpoints', f'best_model_{timestamp}.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# F) Run Hyperparameter Search\n",
    "# -----------------------------\n",
    "print(f\"\\nStarting hyperparameter search. TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(f\"To view TensorBoard, run: tensorboard --logdir {log_dir}\")\n",
    "tuner.search(\n",
    "    train_datagen.flow_from_directory(\n",
    "        directory=TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=8,  # Fixed batch size\n",
    "        class_mode='categorical'\n",
    "    ),\n",
    "    validation_data=val_datagen.flow_from_directory(\n",
    "        directory=VAL_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=8,  # Fixed batch size\n",
    "        class_mode='categorical'\n",
    "    ),\n",
    "    callbacks=search_callbacks,  # Use search callbacks without checkpoint\n",
    "    epochs=100  # Fixed epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# G) Get Best Hyperparameters\n",
    "# -----------------------------\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"L2 Regularization: {best_hps.get('l2_reg')}\")\n",
    "print(f\"Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Dense Units 1: {best_hps.get('dense_units_1')}\")\n",
    "print(f\"Dense Units 2: {best_hps.get('dense_units_2')}\")\n",
    "print(f\"Dense Units 3: {best_hps.get('dense_units_3')}\")\n",
    "print(f\"Learning Rate: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train Final Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining final model with best hyperparameters...\")\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    train_datagen.flow_from_directory(\n",
    "        directory=TRAIN_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=8,  # Fixed batch size\n",
    "        class_mode='categorical'\n",
    "    ),\n",
    "    validation_data=val_datagen.flow_from_directory(\n",
    "        directory=VAL_DIR,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=8,  # Fixed batch size\n",
    "        class_mode='categorical'\n",
    "    ),\n",
    "    epochs=50,  # Fixed epochs\n",
    "    callbacks=final_callbacks  # Use final callbacks with checkpoint\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model.save('best_model_tuned.h5')\n",
    "print(f\"\\nTraining complete! Model saved as 'best_model_tuned.h5'\")\n",
    "print(f\"To view training metrics in TensorBoard, run: tensorboard --logdir logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set and Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# I) Evaluate on Test Set and Plot Confusion Matrix\n",
    "# -----------------------------\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=8,  # Fixed batch size\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Compute and plot confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix - Best Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_best_model.png')\n",
    "plt.close()\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
